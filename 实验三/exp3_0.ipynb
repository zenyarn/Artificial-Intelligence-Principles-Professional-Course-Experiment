{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "尝试使用 gbk 编码读取...\n",
      "gbk 编码读取失败\n",
      "\n",
      "尝试使用 gb18030 编码读取...\n",
      "gb18030 编码读取失败\n",
      "\n",
      "尝试使用 latin1 编码读取...\n",
      "成功使用 latin1 编码读取数据!\n",
      "\n",
      "数据集大小:\n",
      "训练集: (6072, 2)\n",
      "验证集: (867, 2)\n",
      "测试集: (1736, 3)\n",
      "\n",
      "训练集示例:\n",
      "   type                                              posts\n",
      "0  ENFP  Its a bizarre condition of mine, gets me into ...\n",
      "1  ISTP  'wonder are they huggable.. :unsure: I'll try ...\n",
      "2  ENTJ  'Hi ! There is some material in your answer to...\n",
      "3  ENFP  'This is great and makes a lot of sense, I fee...\n",
      "4  INFJ  'so he is not Mr Right? I mean, I thought INFJ...\n",
      "\n",
      "MBTI类型分布:\n",
      "type\n",
      "INFP    1276\n",
      "INFJ    1044\n",
      "INTP     877\n",
      "INTJ     771\n",
      "ENFP     481\n",
      "ENTP     479\n",
      "ISTP     247\n",
      "ISFP     197\n",
      "ENTJ     169\n",
      "ISTJ     135\n",
      "ENFJ     132\n",
      "ISFJ     110\n",
      "ESTP      64\n",
      "ESTJ      31\n",
      "ESFJ      30\n",
      "ESFP      29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "检查缺失值:\n",
      "type     0\n",
      "posts    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文显示\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS']  # macOS\n",
    "# plt.rcParams['font.family'] = ['SimHei']  # Windows\n",
    "\n",
    "# 读取数据 - 尝试不同的编码方式\n",
    "encodings = ['gbk', 'gb18030', 'latin1', 'iso-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        print(f\"\\n尝试使用 {encoding} 编码读取...\")\n",
    "        train_df = pd.read_csv('train.csv', encoding=encoding)\n",
    "        valid_df = pd.read_csv('valid.csv', encoding=encoding)\n",
    "        test_df = pd.read_csv('test.csv', encoding=encoding)\n",
    "        print(f\"成功使用 {encoding} 编码读取数据!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"{encoding} 编码读取失败\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"发生其他错误: {e}\")\n",
    "        continue\n",
    "else:\n",
    "    raise Exception(\"所有编码方式都失败了，请检查文件编码格式\")\n",
    "\n",
    "# 显示数据基本信息\n",
    "print(\"\\n数据集大小:\")\n",
    "print(f\"训练集: {train_df.shape}\")\n",
    "print(f\"验证集: {valid_df.shape}\")\n",
    "print(f\"测试集: {test_df.shape}\")\n",
    "\n",
    "# 显示训练集的前几条数据\n",
    "print(\"\\n训练集示例:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 统计训练集中各MBTI类型的分布\n",
    "print(\"\\nMBTI类型分布:\")\n",
    "print(train_df['type'].value_counts())\n",
    "\n",
    "# 检查是否有缺失值\n",
    "print(\"\\n检查缺失值:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b07124beba4ee0ba3d44f06e2eedb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf31ec058249bab203ce22f1fea189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137298f5004f4798bcd7066f0f6ff426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83a24529f684b8fb41223be11f2077e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射:\n",
      "{'ENFJ': 0, 'ENFP': 1, 'ENTJ': 2, 'ENTP': 3, 'ESFJ': 4, 'ESFP': 5, 'ESTJ': 6, 'ESTP': 7, 'INFJ': 8, 'INFP': 9, 'INTJ': 10, 'INTP': 11, 'ISFJ': 12, 'ISFP': 13, 'ISTJ': 14, 'ISTP': 15}\n",
      "\n",
      "类别数量: 16\n",
      "\n",
      "样本格式:\n",
      "input_ids: torch.Size([512])\n",
      "attention_mask: torch.Size([512])\n",
      "labels: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建自定义数据集类\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # 创建MBTI类型到数字的映射\n",
    "        self.label2id = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
    "        self.id2label = {idx: label for label, idx in self.label2id.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 将文本转换为BERT的输入格式\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.label2id[label])\n",
    "        }\n",
    "\n",
    "# 2. 初始化tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 3. 创建数据集实例\n",
    "train_dataset = MBTIDataset(train_df['posts'].values, train_df['type'].values, tokenizer)\n",
    "valid_dataset = MBTIDataset(valid_df['posts'].values, valid_df['type'].values, tokenizer)\n",
    "\n",
    "print(f\"标签映射:\\n{train_dataset.label2id}\")\n",
    "print(f\"\\n类别数量: {len(train_dataset.label2id)}\")\n",
    "\n",
    "# 4. 检查一个样本的格式\n",
    "sample = train_dataset[0]\n",
    "print(\"\\n样本格式:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e43362f483441d91239471991eaeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练批次大小: 16\n",
      "训练集批次数: 380\n",
      "验证集批次数: 55\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "\n",
    "class MBTIClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=16):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MBTIClassifier()\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"使用设备: {device}\")\n",
    "print(f\"训练批次大小: {batch_size}\")\n",
    "print(f\"训练集批次数: {len(train_loader)}\")\n",
    "print(f\"验证集批次数: {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练批次大小: 32\n",
      "训练集批次数: 190\n",
      "验证集批次数: 28\n",
      "\n",
      "开始训练...\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 190/190 [3:10:00<00:00, 60.00s/it, loss=0.0720, acc=0.2330]    \n",
      "Evaluating: 100%|██████████| 28/28 [00:59<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3020, Train Acc: 0.2330\n",
      "Val Loss: 2.1654, Val Acc: 0.3022\n",
      "新的最佳验证准确率: 0.3022\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 190/190 [1:06:21<00:00, 20.96s/it, loss=0.0615, acc=0.3910] \n",
      "Evaluating: 100%|██████████| 28/28 [01:36<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9653, Train Acc: 0.3910\n",
      "Val Loss: 1.8475, Val Acc: 0.4268\n",
      "新的最佳验证准确率: 0.4268\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 190/190 [36:32<00:00, 11.54s/it, loss=0.0526, acc=0.4975] \n",
      "Evaluating: 100%|██████████| 28/28 [00:55<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6795, Train Acc: 0.4975\n",
      "Val Loss: 1.7048, Val Acc: 0.4798\n",
      "新的最佳验证准确率: 0.4798\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 9/190 [01:48<35:38, 11.82s/it, loss=0.0451, acc=0.5972]"
     ]
    }
   ],
   "source": [
    "# 检查并设置MPS设备\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 初始化模型\n",
    "model = MBTIClassifier()\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练参数\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "best_val_acc = 0\n",
    "best_model = None\n",
    "\n",
    "# 创建数据加载器 - 移除多进程加载\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"训练批次大小: {batch_size}\")\n",
    "print(f\"训练集批次数: {len(train_loader)}\")\n",
    "print(f\"验证集批次数: {len(valid_loader)}\")\n",
    "\n",
    "# 添加进度条显示\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 添加进度条\n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        # 将数据移到指定设备\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # 更新进度条\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{total_loss/total:.4f}',\n",
    "            'acc': f'{correct/total:.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(valid_loader), correct / total\n",
    "\n",
    "# 训练循环\n",
    "print(\"\\n开始训练...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model = model.state_dict().copy()\n",
    "        print(f'新的最佳验证准确率: {best_val_acc:.4f}')\n",
    "    print('-' * 50)\n",
    "\n",
    "print(f'\\n训练完成! 最佳验证准确率: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查并设置MPS设备\n",
    "device = torch.device(\"cpu\")\n",
    "# device = (\n",
    "#     torch.device(\"mps\") \n",
    "#     if torch.backends.mps.is_available() \n",
    "#     else torch.device(\"cpu\")\n",
    "# )\n",
    "\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 初始化模型\n",
    "model = MBTIClassifier()\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练参数 - 减小batch_size和max_length\n",
    "batch_size = 8  # 减小batch size\n",
    "max_length = 256  # 减小序列长度\n",
    "\n",
    "# 重新创建数据集实例，使用较小的max_length\n",
    "train_dataset = MBTIDataset(train_df['posts'].values, train_df['type'].values, tokenizer, max_length=max_length)\n",
    "valid_dataset = MBTIDataset(valid_df['posts'].values, valid_df['type'].values, tokenizer, max_length=max_length)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"训练批次大小: {batch_size}\")\n",
    "print(f\"最大序列长度: {max_length}\")\n",
    "print(f\"训练集批次数: {len(train_loader)}\")\n",
    "print(f\"验证集批次数: {len(valid_loader)}\")\n",
    "\n",
    "# 添加梯度裁剪以提高稳定性\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        # 添加梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # 清理缓存\n",
    "        if device.type == 'mps':\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{total_loss/total:.4f}',\n",
    "            'acc': f'{correct/total:.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # 清理缓存\n",
    "            if device.type == 'mps':\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    return total_loss / len(valid_loader), correct / total\n",
    "\n",
    "# 训练循环\n",
    "print(\"\\n开始训练...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model = model.state_dict().copy()\n",
    "        print(f'新的最佳验证准确率: {best_val_acc:.4f}')\n",
    "    print('-' * 50)\n",
    "\n",
    "print(f'\\n训练完成! 最佳验证准确率: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
